{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "8xPn58GkU-m3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "uGcLcRt1WjRr"
      },
      "outputs": [],
      "source": [
        "path_to_file = tf.keras.utils.get_file('CarlJung.txt', 'https://www.gutenberg.org/files/65903/65903-0.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R54bS-jEXtLC",
        "outputId": "735b5a90-015c-47bb-8b74-aacf622df408"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1154001 characters\n"
          ]
        }
      ],
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "Mm0CZ-NGiKNF"
      },
      "outputs": [],
      "source": [
        "text = text[91540:865250]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "ZT9H5MRd3XWm"
      },
      "outputs": [],
      "source": [
        "vocab = sorted(set(text))\n",
        "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)\n",
        "chars_from_ids = tf.keras.layers.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "9Xv79PoZ8V15"
      },
      "outputs": [],
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "HTYvtDlMAJCE"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\n",
        "\n",
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "UYD-lQCeDJXd"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKvVa3kcTAHH",
        "outputId": "9e148ccc-df40-4bbc-93d2-3bee266a8221"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "    \n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "bwlVkhi0UBaL"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 512\n",
        "rnn_units = 2048"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "jYKsoVbEWjrP"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "QKxJXPgIWnrY"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "hzXgC8_BSbcL"
      },
      "outputs": [],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "jRXLQCDmU5Q6"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "PoiDRPncVGma"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfqMp5lQVVyR",
        "outputId": "41927034-b71a-41a7-8eb9-a396cb2f9897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "119/119 [==============================] - 60s 437ms/step - loss: 3.0621\n",
            "Epoch 2/30\n",
            "119/119 [==============================] - 53s 438ms/step - loss: 2.1256\n",
            "Epoch 3/30\n",
            "119/119 [==============================] - 53s 437ms/step - loss: 1.8550\n",
            "Epoch 4/30\n",
            "119/119 [==============================] - 53s 437ms/step - loss: 1.6542\n",
            "Epoch 5/30\n",
            "119/119 [==============================] - 53s 438ms/step - loss: 1.5152\n",
            "Epoch 6/30\n",
            "119/119 [==============================] - 53s 437ms/step - loss: 1.4200\n",
            "Epoch 7/30\n",
            "119/119 [==============================] - 53s 437ms/step - loss: 1.3460\n",
            "Epoch 8/30\n",
            "119/119 [==============================] - 53s 436ms/step - loss: 1.2861\n",
            "Epoch 9/30\n",
            "119/119 [==============================] - 53s 437ms/step - loss: 1.2312\n",
            "Epoch 10/30\n",
            "119/119 [==============================] - 53s 437ms/step - loss: 1.1798\n",
            "Epoch 11/30\n",
            "119/119 [==============================] - 53s 437ms/step - loss: 1.1273\n",
            "Epoch 12/30\n",
            "119/119 [==============================] - 53s 436ms/step - loss: 1.0733\n",
            "Epoch 13/30\n",
            "119/119 [==============================] - 53s 436ms/step - loss: 1.0166\n",
            "Epoch 14/30\n",
            "119/119 [==============================] - 53s 436ms/step - loss: 0.9571\n",
            "Epoch 15/30\n",
            "119/119 [==============================] - 53s 436ms/step - loss: 0.8907\n",
            "Epoch 16/30\n",
            "119/119 [==============================] - 53s 437ms/step - loss: 0.8239\n",
            "Epoch 17/30\n",
            "119/119 [==============================] - 53s 437ms/step - loss: 0.7519\n",
            "Epoch 18/30\n",
            "119/119 [==============================] - 53s 437ms/step - loss: 0.6786\n",
            "Epoch 19/30\n",
            "119/119 [==============================] - 53s 437ms/step - loss: 0.6023\n",
            "Epoch 20/30\n",
            "119/119 [==============================] - 53s 436ms/step - loss: 0.5296\n",
            "Epoch 21/30\n",
            "119/119 [==============================] - 53s 436ms/step - loss: 0.4561\n",
            "Epoch 22/30\n",
            "119/119 [==============================] - 53s 436ms/step - loss: 0.3901\n",
            "Epoch 23/30\n",
            "119/119 [==============================] - 53s 436ms/step - loss: 0.3303\n",
            "Epoch 24/30\n",
            "119/119 [==============================] - 53s 437ms/step - loss: 0.2816\n",
            "Epoch 25/30\n",
            "119/119 [==============================] - 53s 436ms/step - loss: 0.2391\n",
            "Epoch 26/30\n",
            "119/119 [==============================] - 53s 435ms/step - loss: 0.2034\n",
            "Epoch 27/30\n",
            "119/119 [==============================] - 53s 435ms/step - loss: 0.1768\n",
            "Epoch 28/30\n",
            "119/119 [==============================] - 53s 436ms/step - loss: 0.1570\n",
            "Epoch 29/30\n",
            "119/119 [==============================] - 53s 437ms/step - loss: 0.1433\n",
            "Epoch 30/30\n",
            "119/119 [==============================] - 53s 436ms/step - loss: 0.1331\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "ME7T8DnpVZ6s"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "_VVp2OLeaAVR"
      },
      "outputs": [],
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0Yf_DwFaD67",
        "outputId": "b6df899d-35a8-4a1d-b755-529f6eb6dfa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for power. Nietzsche, in\r\n",
            "Hindoo from her spoken and realismed forth. If only then like Anax ragressed\r\n",
            "in the Argumus tear the age of Thebes, the “maternal difficulty,” but in\r\n",
            "Job,’avakat’s meaning “ferund” in striving adult manifestations, fire.\r\n",
            "They from the development of the Roman Cyptice of the\r\n",
            "Sanskrit “every one seem” in conditional singed, is seted examples.\r\n",
            "\r\n",
            "The religious recrates of the Ares of Whales are marriage with encoiling hardly\r\n",
            "creation results,\r\n",
            "also in the chest resistance, the religious embraces character of\r\n",
            "which elessive and especially dreams which once evolture. The remarkable\r\n",
            "spiritual residestance sexuality and essentially originally\r\n",
            "investigations are corresponditionally discovered, the\r\n",
            "evening of earlier and eftentrates characteristically.\r\n",
            "\r\n",
            "  _Meeding upon the condemned has animat\r\n",
            "  and entrance you had prosirely as a flame of\r\n",
            "  generation.” The largest Prospial and enemy and instrument\r\n",
            "  also of searched (as a manality, growing attimitated above, all every\r\n",
            "  earlier sense over the meanings are very\r\n",
            "  claimed. It is said of the multiplic cond to\r\n",
            "vihat one has its reariente and prove over at the point\r\n",
            "of earthy in the maternal death (spring) of the archers or as\r\n",
            "the problem of Awa. The legend of Phausanos, horse\r\n",
            "forces the person of any of it setting here during the\r\n",
            "correctness of the idea of a present modern\r\n",
            "meaning:\r\n",
            "\r\n",
            "  “_The world, dreaming experience, into\r\n",
            "  prisonged many emarapsed at every day mythicks are formed the\r\n",
            "employed of the hand, then the\r\n",
            "  maressing she were the loight forms off\r\n",
            "  merely _pan perfectly “psychoiced one locks,\r\n",
            "  necessitation of every man science he Thearing of the\r\n",
            "  sicks” on the conception of a clouds served over the\r\n",
            "  highest people, wherein any occurred to mine\r\n",
            "  at the book of the _esear of his mother\r\n",
            "  again the counterful sounds of the earth\r\n",
            "  beautiful them offer umpulses clearly in more.\r\n",
            "\r\n",
            "  (8) “Heaven and you born harmory words for what the\r\n",
            "  prased them marriage J \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 13.822076320648193\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['for'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(2000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PotU-generating.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPh9icBujtmmlUIS+0mqL0f"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}